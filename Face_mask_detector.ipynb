{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face mask detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkdf2GwoWXnq",
        "outputId": "14f8d61b-5b1d-4485-a30c-28a166ef37f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPL2x16sWkDm",
        "outputId": "456f86ee-44e2-4907-8b91-4a04bee433e5"
      },
      "source": [
        "cd drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9uRUAqsW5qs",
        "outputId": "8898467f-65dd-4129-9086-6fab4518c26f"
      },
      "source": [
        "cd MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYd60ROaXETf",
        "outputId": "faaf2619-71ea-4d47-9bee-a46be6c898e6"
      },
      "source": [
        "cd experiements/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/experiements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPn1vTMWJz3E",
        "outputId": "3c3b9bc5-d080-448c-b025-29e53a136550"
      },
      "source": [
        "cd data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/experiements/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGZfy76oWBw2",
        "outputId": "bd75bd39-f941-452d-e3a7-45d0b056d6c9"
      },
      "source": [
        "import cv2,os\n",
        "data_path = os.getcwd() \n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "\n",
        "label_dict=dict(zip(categories,labels)) \n",
        "\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/experiements/data\n",
            "{'with_mask': 0, 'without_mask': 1}\n",
            "['with_mask', 'without_mask']\n",
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmP85of8WQcS"
      },
      "source": [
        "img_size=100\n",
        "data=[]\n",
        "target=[]\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)    \n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "        try:\n",
        "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n",
        "            resized=cv2.resize(gray,(img_size,img_size))\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLW2iYHdYfmV"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target=np.array(target)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "new_target=np_utils.to_categorical(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Udzr4TbYkC6"
      },
      "source": [
        "np.save('data',data)\n",
        "np.save('target',new_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csMrusKYYlVs"
      },
      "source": [
        "data=np.load('data.npy')\n",
        "target=np.load('target.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cBwUR37YysC"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(100,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FNxNUOPY0fq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9pZN9boY3z_",
        "outputId": "83951517-6c25-455d-8797-8e5a5c942fa3"
      },
      "source": [
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
        "history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.7598 - accuracy: 0.5212WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: model-001.model/assets\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.7598 - accuracy: 0.5212 - val_loss: 0.6891 - val_accuracy: 0.5766\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.6680 - accuracy: 0.6182INFO:tensorflow:Assets written to: model-002.model/assets\n",
            "31/31 [==============================] - 76s 2s/step - loss: 0.6680 - accuracy: 0.6182 - val_loss: 0.6352 - val_accuracy: 0.6290\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7576INFO:tensorflow:Assets written to: model-003.model/assets\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.5238 - accuracy: 0.7576 - val_loss: 0.5168 - val_accuracy: 0.7419\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.8263INFO:tensorflow:Assets written to: model-004.model/assets\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.4089 - accuracy: 0.8263 - val_loss: 0.4237 - val_accuracy: 0.7863\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.3268 - accuracy: 0.8646 - val_loss: 0.4254 - val_accuracy: 0.7782\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.9152INFO:tensorflow:Assets written to: model-006.model/assets\n",
            "31/31 [==============================] - 78s 3s/step - loss: 0.2088 - accuracy: 0.9152 - val_loss: 0.3346 - val_accuracy: 0.8589\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9293INFO:tensorflow:Assets written to: model-007.model/assets\n",
            "31/31 [==============================] - 76s 2s/step - loss: 0.1898 - accuracy: 0.9293 - val_loss: 0.3094 - val_accuracy: 0.8508\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9374INFO:tensorflow:Assets written to: model-008.model/assets\n",
            "31/31 [==============================] - 77s 2s/step - loss: 0.1841 - accuracy: 0.9374 - val_loss: 0.2655 - val_accuracy: 0.8911\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.1437 - accuracy: 0.9374 - val_loss: 0.3600 - val_accuracy: 0.8548\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9657INFO:tensorflow:Assets written to: model-010.model/assets\n",
            "31/31 [==============================] - 76s 2s/step - loss: 0.1033 - accuracy: 0.9657 - val_loss: 0.2484 - val_accuracy: 0.9032\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.0833 - accuracy: 0.9727 - val_loss: 0.2654 - val_accuracy: 0.9032\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9838INFO:tensorflow:Assets written to: model-012.model/assets\n",
            "31/31 [==============================] - 76s 2s/step - loss: 0.0583 - accuracy: 0.9838 - val_loss: 0.1698 - val_accuracy: 0.9315\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.0736 - accuracy: 0.9717 - val_loss: 0.2530 - val_accuracy: 0.9032\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 76s 2s/step - loss: 0.0653 - accuracy: 0.9798 - val_loss: 0.2055 - val_accuracy: 0.9395\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 74s 2s/step - loss: 0.0574 - accuracy: 0.9778 - val_loss: 0.1953 - val_accuracy: 0.9395\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.0469 - accuracy: 0.9818 - val_loss: 0.2123 - val_accuracy: 0.9234\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9929INFO:tensorflow:Assets written to: model-017.model/assets\n",
            "31/31 [==============================] - 76s 2s/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.1640 - val_accuracy: 0.9355\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.1959 - val_accuracy: 0.9395\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.2157 - val_accuracy: 0.9274\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 75s 2s/step - loss: 0.0238 - accuracy: 0.9960 - val_loss: 0.3556 - val_accuracy: 0.8871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAeitTpZY7HW",
        "outputId": "2c9fb420-88f9-4567-fa33-8c92cd857328"
      },
      "source": [
        "print(model.evaluate(test_data,test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 448ms/step - loss: 0.2302 - accuracy: 0.9420\n",
            "[0.23017875850200653, 0.9420289993286133]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yTKF7GcZA3A"
      },
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9gS0HVNz6MQ"
      },
      "source": [
        "from IPython.display import HTML, Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "video_file_test = '/content/Video/osy_test.mp4' \n",
        "  \n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var my_btn_txt = document.createTextNode(\"Press to start recording\");\n",
        "my_btn.appendChild(my_btn_txt);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, videoStream;\n",
        "var recordButton = my_btn;\n",
        "var handleSuccess = function(stream) {\n",
        "  videoStream = stream;\n",
        "  var options = {  \n",
        "    mimeType : 'video/webm;codecs=vp9'  \n",
        "  };            \n",
        "  recorder = new MediaRecorder(stream, options);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('video');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      videoStream.getVideoTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... Please wait!\"\n",
        "  }\n",
        "}\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available\n",
        "  resolve(base64data.toString())\n",
        "});\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def start_webcam():\n",
        "  js = Javascript('''\n",
        "    async function startWebcam() {\n",
        "      const div = document.createElement('div');\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      \n",
        "      return;\n",
        "    }\n",
        "    ''')\n",
        "  \n",
        "  display(js)\n",
        "  data = eval_js('startWebcam()')\n",
        "      \n",
        "\n",
        "def get_video():\n",
        "  display(HTML(VIDEO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  return binary\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSjaXpptZCtd"
      },
      "source": [
        "model = load_model('model-017.model')\n",
        "\n",
        "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "source=cv2.VideoCapture(0)\n",
        "  \n",
        "labels_dict={0:'MASK',1:'NO MASK'}\n",
        "color_dict={0:(0,255,0),1:(0,0,255)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF1EYU-oHWvX"
      },
      "source": [
        "while(True):\n",
        "\n",
        "    ret,img=source.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    frame_count += 1     \n",
        "    img = cv2.flip(img, 1)       \n",
        "    face = face_cascade.detectMultiScale(frame, 1.3, 5)  \n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "    \n",
        "        face_img=gray[y:y+w,x:x+w]\n",
        "        resized=cv2.resize(face_img,(100,100))\n",
        "        normalized=resized/255.0\n",
        "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
        "        result=model.predict(reshaped)\n",
        "\n",
        "        label=np.argmax(result,axis=1)[0]\n",
        "      \n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
        "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
        "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "        \n",
        "        \n",
        "    cv2.imshow('LIVE',img)\n",
        "    key=cv2.waitKey(1)\n",
        "    \n",
        "    if(key==27):\n",
        "        break\n",
        "        \n",
        "cv2.destroyAllWindows()\n",
        "source.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}